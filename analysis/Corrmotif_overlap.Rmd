---
title: "Corrmotif overlap"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## **ðŸ“Œ Overlap of genes between corrmotif Conc. 0.1 and 0.5**
```{r 0verlap_conc., echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}
library(UpSetR)
library(dplyr)

# Load gene sets
prob_1_0.1 <- as.character(read.csv("data/prob_1_0.1.csv")$Entrez_ID)
prob_2_0.1 <- as.character(read.csv("data/prob_2_0.1.csv")$Entrez_ID)
prob_3_0.1 <- as.character(read.csv("data/prob_3_0.1.csv")$Entrez_ID)

prob_1_0.5 <- as.character(read.csv("data/prob_1_0.5.csv")$Entrez_ID)
prob_2_0.5 <- as.character(read.csv("data/prob_2_0.5.csv")$Entrez_ID)
prob_3_0.5 <- as.character(read.csv("data/prob_3_0.5.csv")$Entrez_ID)
prob_4_0.5 <- as.character(read.csv("data/prob_4_0.5.csv")$Entrez_ID)
prob_5_0.5 <- as.character(read.csv("data/prob_5_0.5.csv")$Entrez_ID)

# Label gene sets (no \n)
gene_sets <- list(
  `Non response (0.1 ÂµM)` = prob_1_0.1,
  `CX-DOX mid-late response (0.1 ÂµM)` = prob_2_0.1,
  `DOX only mid-late response (0.1 ÂµM)` = prob_3_0.1,
  `Non response (0.5 ÂµM)` = prob_1_0.5,
  `DOX-specific response (0.5 ÂµM)` = prob_2_0.5,
  `DOX only mid-late response (0.5 ÂµM)` = prob_3_0.5,
  `CX + DOX early response (0.5 ÂµM)` = prob_4_0.5,
  `DOX + CX (mid-late) response (0.5 ÂµM)` = prob_5_0.5
)

# Prepare universe
all_genes <- unique(unlist(gene_sets))

# Build binary matrix
binary_matrix <- data.frame(Gene = all_genes)
for (name in names(gene_sets)) {
  binary_matrix[[name]] <- as.integer(binary_matrix$Gene %in% gene_sets[[name]])
}
binary_matrix <- binary_matrix[, -1]  # Remove Gene column

# Set larger bottom margin before plotting
par(mar = c(10, 4, 2, 2))  # bottom, left, top, right

# Then plot
upset(binary_matrix,
      sets = names(gene_sets),
      order.by = "freq",
      sets.bar.color = "#56B4E9",
      mainbar.y.label = "Number of Shared Genes",
      sets.x.label = "Genes per Set",
      text.scale = 1.2,
      nintersects = 30)
```

## **ðŸ“Œ Overlap of CX associate groups**
```{r 0verlap_CX., echo=TRUE, message=FALSE, warning=FALSE}
# Load required library
library(ggVennDiagram)
library(ggplot2)

# Load gene sets
prob_2_0.1 <- as.character(read.csv("data/prob_2_0.1.csv")$Entrez_ID)
prob_4_0.5 <- as.character(read.csv("data/prob_4_0.5.csv")$Entrez_ID)
prob_5_0.5 <- as.character(read.csv("data/prob_5_0.5.csv")$Entrez_ID)

# Define gene sets with exact labels
venn_list <- list(
  `CX-DOX mid-late\nresponse (0.1 ÂµM)` = prob_2_0.1,
  `CX total + DOX early\nresponse (0.5 ÂµM)` = prob_4_0.5,
  `DOX early+ CX-DOX mid-late\nresponse (0.5 ÂµM)` = prob_5_0.5
)

# Build plot object
p <- ggVennDiagram(
  venn_list,
  label_alpha = 0.6,
  label = "count"
) +
  scale_fill_gradient(low = "#08306B", high = "#6BAED6") +
  theme(legend.position = "right")

# Manually reduce set label size (layer 3 is usually the set label layer)
p$layers[[3]]$aes_params$size <- 2.5

# Render the final plot
p
```

## **ðŸ“Œ Overlap of GO functions between Corrmotif all and corrmotif Conc.**
```{r 0verlap, echo=TRUE, message=FALSE, warning=FALSE, fig.height=6, fig.width=10}

library(UpSetR)
library(dplyr)
library(tools)
library(GO.db)

# Set the folder path
folder_path <- "data/all_GO"

# Get a list of all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Loop through each file and assign it as a variable in the global environment
for (file in csv_files) {
  # Generate a valid R variable name from the file name (remove extension and replace spaces)
  file_name <- tools::file_path_sans_ext(basename(file))
  file_name <- gsub(" ", "_", file_name)  # Replace spaces with underscores
  file_name <- make.names(file_name)  # Ensure the name is valid in R
  
  # Assign the CSV file as a variable in the environment
  assign(file_name, read.csv(file, stringsAsFactors = FALSE))
}

# Define datasets (lists of Entrez Gene IDs)
sets <- list(
  "Non response all" = prob_all_1$ID,
  "CX_DOX shared late response all" = prob_all_2$ID,
  "Dox specific response all" = prob_all_3$ID,
  "Late high dose DOX specific response all" = prob_all_4$ID,
  
  "Non response (0.1)" = prob_1_0.1$ID,
  "CX_DOX mid-late (0.1)" = prob_2_0.1$ID,
  "DOX only mid-late (0.1)" = prob_3_0.1$ID,
  "Non response (0.5)" = prob_1_0.5$ID,
  "DOX only early-mid (0.5)" = prob_2_0.5$ID,
  "DOX only mid-late (0.5)" = prob_3_0.5$ID,
  "CX only mid-late (0.5)" = prob_4_0.5$ID,
  "CX_DOX mid-late (0.5)" = prob_5_0.5$ID
)

# Create a binary matrix for UpSet plot
all_genes <- unique(unlist(sets))  # Get all unique Entrez Gene IDs
binary_matrix <- data.frame(Gene_ID = all_genes)  # Initialize DataFrame

# Convert gene lists into a presence/absence matrix (1 = present, 0 = absent)
for (set_name in names(sets)) {
  binary_matrix[[set_name]] <- as.integer(all_genes %in% sets[[set_name]])
}

# Remove Gene_ID column as UpSetR only needs the binary matrix
binary_matrix <- binary_matrix[, -1]

upset(binary_matrix,
      sets = names(sets),
      order.by = "freq",
      sets.bar.color = "#56B4E9",  # Blue bars for set sizes
      mainbar.y.label = "Number of Shared Functions",
      sets.x.label = "GO terms per set",
      text.scale = 1.2,
      nintersects = 30)
```

## **ðŸ“Œ Identify Unique GO Terms for Each Response Group**
```{r Unique GO Terms, echo=TRUE, message=FALSE}
# Create a list to store unique GO terms per category
unique_go_terms <- list()

# Loop through each set to find unique GO terms
for (set_name in names(sets)) {
  # Get the GO terms for the current set
  current_go_terms <- sets[[set_name]]
  
  # Find GO terms that appear **only** in this set and not in others
  unique_terms <- current_go_terms[!(current_go_terms %in% unlist(sets[names(sets) != set_name]))]
  
  # Store in the list if there are any unique terms
  if (length(unique_terms) > 0) {
    unique_go_terms[[set_name]] <- unique_terms
  }
}

# Display unique GO terms for each category
unique_go_terms
```

## **ðŸ“Œ Map GO IDs to Function Names Using GO.db**
```{r MAP GO Terms, echo=TRUE, message=FALSE}
map_go_terms_local <- function(go_ids) {
  go_names <- unlist(mget(go_ids, GOTERM, ifnotfound = NA))  # Retrieve function names
  go_descriptions <- sapply(go_names, function(x) if (!is.na(x)) Term(x) else NA)
  
  # Create a dataframe
  go_mapping <- data.frame(GO_ID = go_ids, Function = go_descriptions, stringsAsFactors = FALSE)
  
  # Remove NAs (unrecognized GO IDs)
  go_mapping <- go_mapping[!is.na(go_mapping$Function), ]
  
  return(go_mapping)
}
mapped_unique_go_terms <- list()

for (set_name in names(unique_go_terms)) {
  if (length(unique_go_terms[[set_name]]) > 0) {
    go_data <- map_go_terms_local(unique_go_terms[[set_name]])
    mapped_unique_go_terms[[set_name]] <- go_data
  }
}

# Display mapped GO terms
mapped_unique_go_terms
```

## **ðŸ“Œ Overlap of GO functions between DEGs and corrmotif timepoints**
```{r 0verlap2, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

library(UpSetR)
library(dplyr)
library(tools)
library(GO.db)

# Set the folder path
folder_path <- "data/GO_time"

# Get a list of all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Loop through each file and assign it as a variable in the global environment
for (file in csv_files) {
  # Generate a valid R variable name from the file name (remove extension and replace spaces)
  file_name <- tools::file_path_sans_ext(basename(file))
  file_name <- gsub(" ", "_", file_name)  # Replace spaces with underscores
  file_name <- make.names(file_name)  # Ensure the name is valid in R
  
  # Assign the CSV file as a variable in the environment
  assign(file_name, read.csv(file, stringsAsFactors = FALSE))
}

sets <- list(
  "CX_0.1_24" = CX_0.1_24_GO$ID,
  "CX_0.1_48" = CX_0.1_48_GO$ID,
  "CX_0.5_3" = CX_0.5_3_GO$ID,
  "CX_0.5_24" = CX_0.5_24_GO$ID,
  "CX_0.5_48" = CX_0.5_48_GO$ID,
  "DOX_0.1_3" = DOX_0.1_3_GO$ID,
  "DOX_0.1_24" = DOX_0.1_24_GO$ID,
  "DOX_0.1_48" = DOX_0.1_48_GO$ID,
  "DOX_0.5_3" = DOX_0.5_3_GO$ID,
  "DOX_0.5_24" = DOX_0.5_24_GO$ID,
  "DOX_0.5_48" = DOX_0.5_48_GO$ID,
  "CX_low_non_response" = prob_CX_1_0.1_GO$ID,
  "CX_low_mid_late_response" = prob_CX_2_0.1_GO$ID,
  "CX_high_non_response" = prob_CX_1_0.5_GO$ID,
  "CX_high_mid_late_response" = prob_CX_2_0.5_GO$ID,
  "DOX_low_non_response" = prob_DOX_1_0.1_GO$ID,
  "DOX_low_mid_late_response" = prob_DOX_2_0.1_GO$ID,
  "DOX_high_non_response" = prob_DOX_1_0.5_GO$ID,
  "DOX_high_response" = prob_DOX_2_0.5_GO$ID
)

# Create a binary matrix for UpSet plot
all_genes <- unique(unlist(sets))  # Get all unique Entrez Gene IDs
binary_matrix <- data.frame(Gene_ID = all_genes)  # Initialize DataFrame

# Convert gene lists into a presence/absence matrix (1 = present, 0 = absent)
for (set_name in names(sets)) {
  binary_matrix[[set_name]] <- as.integer(all_genes %in% sets[[set_name]])
}

# Remove Gene_ID column as UpSetR only needs the binary matrix
binary_matrix <- binary_matrix[, -1]

upset(binary_matrix,
      sets = names(sets),
      order.by = "freq",
      sets.bar.color = "#56B4E9",  # Blue bars for set sizes
      mainbar.y.label = "Number of Shared Functions",
      sets.x.label = "GO terms per set",
      text.scale = 1.2,
      nintersects = 50)
```

## **ðŸ“Œ Identify Unique GO Terms for Each Response Group**
```{r Unique GO Terms2, echo=TRUE, message=FALSE}
# Create a list to store unique GO terms per category
unique_go_terms <- list()

# Loop through each set to find unique GO terms
for (set_name in names(sets)) {
  # Get the GO terms for the current set
  current_go_terms <- sets[[set_name]]
  
  # Find GO terms that appear **only** in this set and not in others
  unique_terms <- current_go_terms[!(current_go_terms %in% unlist(sets[names(sets) != set_name]))]
  
  # Store in the list if there are any unique terms
  if (length(unique_terms) > 0) {
    unique_go_terms[[set_name]] <- unique_terms
  }
}

# Display unique GO terms for each category
unique_go_terms
```

## **ðŸ“Œ Map GO IDs to Function Names Using GO.db**
```{r MAP GO Terms2, echo=TRUE, message=FALSE}
map_go_terms_local <- function(go_ids) {
  go_names <- unlist(mget(go_ids, GOTERM, ifnotfound = NA))  # Retrieve function names
  go_descriptions <- sapply(go_names, function(x) if (!is.na(x)) Term(x) else NA)
  
  # Create a dataframe
  go_mapping <- data.frame(GO_ID = go_ids, Function = go_descriptions, stringsAsFactors = FALSE)
  
  # Remove NAs (unrecognized GO IDs)
  go_mapping <- go_mapping[!is.na(go_mapping$Function), ]
  
  return(go_mapping)
}
mapped_unique_go_terms <- list()

for (set_name in names(unique_go_terms)) {
  if (length(unique_go_terms[[set_name]]) > 0) {
    go_data <- map_go_terms_local(unique_go_terms[[set_name]])
    mapped_unique_go_terms[[set_name]] <- go_data
  }
}

# Display mapped GO terms
mapped_unique_go_terms
```

## **ðŸ“Œ Overlap of BP functions between cormotif groups (Concentration)**
```{r BP_ol, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=10}

# ðŸ“¦ Load Required Libraries
library(UpSetR)
library(dplyr)

# âœ… Step 1: Define CorMotif GO BP enrichment files
go_files <- list(
  "Non response (0.1)"                         = "data/BP/CorMotif_Terms/GO_BP_Non_response_(0.1).csv",
  "CX-DOX mid-late response (0.1)"             = "data/BP/CorMotif_Terms/GO_BP_CX-DOX_mid-late_response_(0.1).csv",
  "DOX only mid-late (0.1)"                    = "data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_(0.1).csv",
  "Non response (0.5)"                         = "data/BP/CorMotif_Terms/GO_BP_Non_response_(0.5).csv",
  "DOX specific response (0.5)"                = "data/BP/CorMotif_Terms/GO_BP_DOX_specific_response_(0.5).csv",
  "DOX only mid-late response (0.5)"           = "data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_response_(0.5).csv",
  "CX total + DOX early response (0.5)"        = "data/BP/CorMotif_Terms/GO_BP_CX_total_+_DOX_early_response_(0.5).csv",
  "DOX early + CX-DOX mid-late response (0.5)" = "data/BP/CorMotif_Terms/GO_BP_DOX_early_+_CX-DOX_mid-late_response_(0.5).csv"
)

# âœ… Step 2: Read and filter each file (keep only p.adjust < 0.05), extract GO term IDs
gene_sets <- lapply(go_files, function(file) {
  read.csv(file) %>%
    filter(p.adjust < 0.05) %>%
    pull(ID) %>%
    as.character()
})

# ðŸ§® Step 3: Build binary presence/absence matrix
all_ids <- unique(unlist(gene_sets))
binary_matrix <- data.frame(GO_ID = all_ids)

for (group_name in names(gene_sets)) {
  binary_matrix[[group_name]] <- as.integer(binary_matrix$GO_ID %in% gene_sets[[group_name]])
}

# âœ… Step 4: Prepare for UpSetR (remove GO_ID column)
upset_input <- binary_matrix[, -1]
colnames(upset_input) <- names(gene_sets)

# ðŸŽ¯ Step 5: Plot the UpSet diagram
par(mar = c(12, 4, 2, 2))  # Adjust bottom margin for long labels
upset(
  upset_input,
  sets = colnames(upset_input),
  order.by = "freq",
  sets.bar.color = "#1f77b4",
  mainbar.y.label = "Number of Shared GO BP Terms (p.adjust < 0.05)",
  sets.x.label = "GO BP Terms per CorMotif Group",
  text.scale = 1.2,
  nintersects = 30
)
```

## **ðŸ“Œ Identifying Unique GO terms**
```{r BP_ol1, echo=TRUE, message=FALSE, warning=FALSE}
# ðŸ“¦ Load Required Libraries
library(dplyr)

# âœ… Step 1: Define File Paths for CorMotif Groups
go_files <- list(
  "Non response (0.1)"                         = "data/BP/CorMotif_Terms/GO_BP_Non_response_(0.1).csv",
  "CX-DOX mid-late response (0.1)"             = "data/BP/CorMotif_Terms/GO_BP_CX-DOX_mid-late_response_(0.1).csv",
  "DOX only mid-late (0.1)"                    = "data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_(0.1).csv",
  "Non response (0.5)"                         = "data/BP/CorMotif_Terms/GO_BP_Non_response_(0.5).csv",
  "DOX specific response (0.5)"                = "data/BP/CorMotif_Terms/GO_BP_DOX_specific_response_(0.5).csv",
  "DOX only mid-late response (0.5)"           = "data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_response_(0.5).csv",
  "CX total + DOX early response (0.5)"        = "data/BP/CorMotif_Terms/GO_BP_CX_total_+_DOX_early_response_(0.5).csv",
  "DOX early + CX-DOX mid-late response (0.5)" = "data/BP/CorMotif_Terms/GO_BP_DOX_early_+_CX-DOX_mid-late_response_(0.5).csv"
)

# âœ… Step 2: Read and Filter Each File (p.adjust < 0.05)
go_data <- lapply(go_files, function(file) {
  df <- read.csv(file)
  df %>% filter(p.adjust < 0.05)
})

# âœ… Step 3: Identify Unique GO Terms in Each Group
unique_go_terms <- list()

for (group_name in names(go_data)) {
  current_ids <- go_data[[group_name]]$ID
  other_ids <- unlist(lapply(go_data[names(go_data) != group_name], `[[`, "ID"), use.names = FALSE)
  unique_ids <- setdiff(current_ids, other_ids)
  
  if (length(unique_ids) > 0) {
    unique_go_terms[[group_name]] <- unique_ids
  }
}

# âœ… Step 4: Map Unique IDs to Description and p.adjust
mapped_unique_go_terms <- list()

for (group_name in names(unique_go_terms)) {
  df <- go_data[[group_name]]
  unique_ids <- unique_go_terms[[group_name]]
  
  mapped_df <- df %>%
    filter(ID %in% unique_ids) %>%
    dplyr::select(GO_ID = ID, Function = Description, p.adjust)
  
  mapped_unique_go_terms[[group_name]] <- mapped_df
}

# ðŸŽ¯ Final Output: List of data.frames with GO_ID, Function, and p.adjust per CorMotif group
mapped_unique_go_terms
```


## **ðŸ“Œ TOP Unique GO terms**
```{r BP_ol2, echo=TRUE, message=FALSE, warning=FALSE}

# ðŸ“¦ Load Required Libraries
library(dplyr)
library(readr)

# âœ… Step 1: Load and Filter GO Term Data (p.adjust < 0.05) from CorMotif_Terms
GO_Non_response_0.1  <- read_csv("data/BP/CorMotif_Terms/GO_BP_Non_response_(0.1).csv")                         %>% filter(p.adjust < 0.05)
GO_CX_DOX_midlate_0.1 <- read_csv("data/BP/CorMotif_Terms/GO_BP_CX-DOX_mid-late_response_(0.1).csv")           %>% filter(p.adjust < 0.05)
GO_DOX_only_midlate_0.1 <- read_csv("data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_(0.1).csv")                %>% filter(p.adjust < 0.05)

GO_Non_response_0.5  <- read_csv("data/BP/CorMotif_Terms/GO_BP_Non_response_(0.5).csv")                         %>% filter(p.adjust < 0.05)
GO_DOX_specific_0.5  <- read_csv("data/BP/CorMotif_Terms/GO_BP_DOX_specific_response_(0.5).csv")               %>% filter(p.adjust < 0.05)
GO_DOX_only_midlate_0.5 <- read_csv("data/BP/CorMotif_Terms/GO_BP_DOX_only_mid-late_response_(0.5).csv")       %>% filter(p.adjust < 0.05)
GO_CX_total_DOX_early_0.5 <- read_csv("data/BP/CorMotif_Terms/GO_BP_CX_total_+_DOX_early_response_(0.5).csv")   %>% filter(p.adjust < 0.05)
GO_DOX_early_CX_DOX_midlate_0.5 <- read_csv("data/BP/CorMotif_Terms/GO_BP_DOX_early_+_CX-DOX_mid-late_response_(0.5).csv") %>% filter(p.adjust < 0.05)

# âœ… Step 2: Create Named List of Filtered Data Frames
go_files <- list(
  "Non response (0.1)"                         = GO_Non_response_0.1,
  "CX-DOX mid-late response (0.1)"             = GO_CX_DOX_midlate_0.1,
  "DOX only mid-late (0.1)"                    = GO_DOX_only_midlate_0.1,
  "Non response (0.5)"                         = GO_Non_response_0.5,
  "DOX specific response (0.5)"                = GO_DOX_specific_0.5,
  "DOX only mid-late response (0.5)"           = GO_DOX_only_midlate_0.5,
  "CX total + DOX early response (0.5)"        = GO_CX_total_DOX_early_0.5,
  "DOX early + CX-DOX mid-late response (0.5)" = GO_DOX_early_CX_DOX_midlate_0.5
)

# âœ… Step 3: Identify Unique GO Term IDs per CorMotif Group
unique_go_terms <- list()

for (set_name in names(go_files)) {
  current_ids <- go_files[[set_name]]$ID
  other_ids <- unlist(lapply(go_files[names(go_files) != set_name], `[[`, "ID"), use.names = FALSE)
  unique_ids <- setdiff(current_ids, other_ids)
  
  if (length(unique_ids) > 0) {
    unique_go_terms[[set_name]] <- unique_ids
  }
}

# âœ… Step 4: Map Unique GO IDs to Description and p.adjust
mapped_unique_go_terms <- list()

for (set_name in names(unique_go_terms)) {
  source_df <- go_files[[set_name]]
  unique_ids <- unique_go_terms[[set_name]]
  
  mapped_df <- source_df %>%
    filter(ID %in% unique_ids) %>%
    dplyr::select(GO_ID = ID, Function = Description, p.adjust)
  
  if (nrow(mapped_df) > 0) {
    mapped_unique_go_terms[[set_name]] <- mapped_df
  }
}

# ðŸŽ¯ Final Output: Named list of data.frames with unique + significant GO terms per CorMotif group
mapped_unique_go_terms
```

## **ðŸ“Œ Plot Unique GO terms**
```{r BP_ol3, echo=TRUE, message=FALSE, warning=FALSE, fig.width=20, fig.height=10}
# ðŸ“¦ Load Required Libraries
library(dplyr)
library(ggplot2)
library(ggpubr)
library(stringr)

# ðŸ§¾ Input: mapped_unique_go_terms (from previous script)
# This is a named list of data frames with columns: GO_ID, Function, p.adjust

# ðŸ” Step 1: Prepare Top 10 Unique Terms per CorMotif Group
plot_data <- list()

for (set_name in names(mapped_unique_go_terms)) {
  unique_df <- mapped_unique_go_terms[[set_name]]
  
  if (nrow(unique_df) > 0) {
    unique_df <- dplyr::mutate(unique_df,
                               Sample = set_name,
                               NegLog10Padj = -log10(p.adjust))
    
    top10 <- unique_df %>%
      dplyr::slice_min(order_by = p.adjust, n = 10, with_ties = FALSE) %>%
      dplyr::select(Sample, Function, NegLog10Padj)
    
    plot_data[[set_name]] <- top10
  }
}

# ðŸ”— Step 2: Combine and Format for Plotting
plot_df <- bind_rows(plot_data)
plot_df$Function <- str_trunc(plot_df$Function, 60)  # Truncate long GO terms

# ðŸŽ¨ Step 3: Plot Top 10 Barplots by Group
ggplot(plot_df, aes(x = NegLog10Padj, y = reorder(Function, NegLog10Padj))) +
  geom_bar(stat = "identity", fill = "#3182bd") +
  facet_wrap(~ Sample, scales = "free_y", ncol = 2, strip.position = "top") +
  labs(
    x = expression(-log[10]~"(adj. p-value)"),
    y = "GO Biological Process",
    title = "Top 10 Unique Enriched GO BP Terms per CorMotif Group"
  ) +
  theme_pubr(base_size = 14) +
  theme(
    strip.background = element_rect(color = "black", fill = "grey90", size = 1),
    strip.text = element_text(face = "bold"),
    axis.text.y = element_text(size = 10),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```
